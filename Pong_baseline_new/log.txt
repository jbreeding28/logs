Logging to /home/jack/logs/Pong_baseline_new
--------------------------------------
| % time spent exploring  | 91       |
| episodes                | 10       |
| mean 100 episode reward | -20.4    |
| steps                   | 8.25e+03 |
--------------------------------------
--------------------------------------
| % time spent exploring  | 82       |
| episodes                | 20       |
| mean 100 episode reward | -20.3    |
| steps                   | 1.77e+04 |
--------------------------------------
--------------------------------------
| % time spent exploring  | 73       |
| episodes                | 30       |
| mean 100 episode reward | -20.3    |
| steps                   | 2.64e+04 |
--------------------------------------
--------------------------------------
| % time spent exploring  | 65       |
| episodes                | 40       |
| mean 100 episode reward | -20.4    |
| steps                   | 3.53e+04 |
--------------------------------------
--------------------------------------
| % time spent exploring  | 55       |
| episodes                | 50       |
| mean 100 episode reward | -20.4    |
| steps                   | 4.45e+04 |
--------------------------------------
--------------------------------------
| % time spent exploring  | 46       |
| episodes                | 60       |
| mean 100 episode reward | -20.4    |
| steps                   | 5.36e+04 |
--------------------------------------
--------------------------------------
| % time spent exploring  | 38       |
| episodes                | 70       |
| mean 100 episode reward | -20.4    |
| steps                   | 6.26e+04 |
--------------------------------------
--------------------------------------
| % time spent exploring  | 28       |
| episodes                | 80       |
| mean 100 episode reward | -20.5    |
| steps                   | 7.19e+04 |
--------------------------------------
--------------------------------------
| % time spent exploring  | 17       |
| episodes                | 90       |
| mean 100 episode reward | -20.4    |
| steps                   | 8.31e+04 |
--------------------------------------
--------------------------------------
| % time spent exploring  | 3        |
| episodes                | 100      |
| mean 100 episode reward | -20.4    |
| steps                   | 9.72e+04 |
--------------------------------------
Saving model due to mean reward increase: None -> -20.4
Saving model due to mean reward increase: -20.4 -> -20.3
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 110      |
| mean 100 episode reward | -20.3    |
| steps                   | 1.14e+05 |
--------------------------------------
Saving model due to mean reward increase: -20.3 -> -20.2
Saving model due to mean reward increase: -20.2 -> -20.1
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 120      |
| mean 100 episode reward | -20      |
| steps                   | 1.34e+05 |
--------------------------------------
Saving model due to mean reward increase: -20.1 -> -19.9
Saving model due to mean reward increase: -19.9 -> -19.8
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 130      |
| mean 100 episode reward | -19.7    |
| steps                   | 1.56e+05 |
--------------------------------------
Saving model due to mean reward increase: -19.8 -> -19.7
Saving model due to mean reward increase: -19.7 -> -19.5
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 140      |
| mean 100 episode reward | -19.4    |
| steps                   | 1.79e+05 |
--------------------------------------
Saving model due to mean reward increase: -19.5 -> -19.4
Saving model due to mean reward increase: -19.4 -> -19.3
Saving model due to mean reward increase: -19.3 -> -19.1
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 150      |
| mean 100 episode reward | -19.1    |
| steps                   | 2.01e+05 |
--------------------------------------
Saving model due to mean reward increase: -19.1 -> -18.9
Saving model due to mean reward increase: -18.9 -> -18.7
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 160      |
| mean 100 episode reward | -18.3    |
| steps                   | 2.3e+05  |
--------------------------------------
Saving model due to mean reward increase: -18.7 -> -18.3
Saving model due to mean reward increase: -18.3 -> -18.2
Saving model due to mean reward increase: -18.2 -> -17.9
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 170      |
| mean 100 episode reward | -17.5    |
| steps                   | 2.6e+05  |
--------------------------------------
Saving model due to mean reward increase: -17.9 -> -17.5
Saving model due to mean reward increase: -17.5 -> -17.1
Saving model due to mean reward increase: -17.1 -> -16.5
Saving model due to mean reward increase: -16.5 -> -16.0
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 180      |
| mean 100 episode reward | -15.9    |
| steps                   | 2.9e+05  |
--------------------------------------
Saving model due to mean reward increase: -16.0 -> -15.3
Saving model due to mean reward increase: -15.3 -> -14.5
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 190      |
| mean 100 episode reward | -14.1    |
| steps                   | 3.19e+05 |
--------------------------------------
Saving model due to mean reward increase: -14.5 -> -14.1
Saving model due to mean reward increase: -14.1 -> -14.0
Saving model due to mean reward increase: -14.0 -> -13.7
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 200      |
| mean 100 episode reward | -13      |
| steps                   | 3.46e+05 |
--------------------------------------
Saving model due to mean reward increase: -13.7 -> -12.9
Saving model due to mean reward increase: -12.9 -> -12.2
Saving model due to mean reward increase: -12.2 -> -11.8
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 210      |
| mean 100 episode reward | -11.7    |
| steps                   | 3.79e+05 |
--------------------------------------
Saving model due to mean reward increase: -11.8 -> -11.7
Saving model due to mean reward increase: -11.7 -> -11.2
Saving model due to mean reward increase: -11.2 -> -10.6
Saving model due to mean reward increase: -10.6 -> -9.9
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 220      |
| mean 100 episode reward | -9.7     |
| steps                   | 4.13e+05 |
--------------------------------------
Saving model due to mean reward increase: -9.9 -> -9.6
Saving model due to mean reward increase: -9.6 -> -9.0
Saving model due to mean reward increase: -9.0 -> -8.7
Saving model due to mean reward increase: -8.7 -> -8.2
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 230      |
| mean 100 episode reward | -8.1     |
| steps                   | 4.53e+05 |
--------------------------------------
Saving model due to mean reward increase: -8.2 -> -7.8
Saving model due to mean reward increase: -7.8 -> -7.6
Saving model due to mean reward increase: -7.6 -> -7.1
Saving model due to mean reward increase: -7.1 -> -6.7
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 240      |
| mean 100 episode reward | -6.2     |
| steps                   | 4.93e+05 |
--------------------------------------
Saving model due to mean reward increase: -6.7 -> -5.6
Saving model due to mean reward increase: -5.6 -> -4.4
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 250      |
| mean 100 episode reward | -3.1     |
| steps                   | 5.18e+05 |
--------------------------------------
Saving model due to mean reward increase: -4.4 -> -2.7
Saving model due to mean reward increase: -2.7 -> -0.7
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 260      |
| mean 100 episode reward | 0.1      |
| steps                   | 5.36e+05 |
--------------------------------------
Saving model due to mean reward increase: -0.7 -> 0.8
Saving model due to mean reward increase: 0.8 -> 2.2
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 270      |
| mean 100 episode reward | 3        |
| steps                   | 5.56e+05 |
--------------------------------------
Saving model due to mean reward increase: 2.2 -> 3.5
Saving model due to mean reward increase: 3.5 -> 4.6
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 280      |
| mean 100 episode reward | 5.4      |
| steps                   | 5.74e+05 |
--------------------------------------
Saving model due to mean reward increase: 4.6 -> 6.0
Saving model due to mean reward increase: 6.0 -> 7.4
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 290      |
| mean 100 episode reward | 7.7      |
| steps                   | 5.91e+05 |
--------------------------------------
Saving model due to mean reward increase: 7.4 -> 8.9
Saving model due to mean reward increase: 8.9 -> 9.7
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 300      |
| mean 100 episode reward | 10.1     |
| steps                   | 6.12e+05 |
--------------------------------------
Saving model due to mean reward increase: 9.7 -> 10.6
Saving model due to mean reward increase: 10.6 -> 12.1
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 310      |
| mean 100 episode reward | 12.5     |
| steps                   | 6.31e+05 |
--------------------------------------
Saving model due to mean reward increase: 12.1 -> 13.3
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 320      |
| mean 100 episode reward | 14.2     |
| steps                   | 6.49e+05 |
--------------------------------------
Saving model due to mean reward increase: 13.3 -> 14.2
Saving model due to mean reward increase: 14.2 -> 15.2
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 330      |
| mean 100 episode reward | 16.2     |
| steps                   | 6.68e+05 |
--------------------------------------
Saving model due to mean reward increase: 15.2 -> 16.2
Saving model due to mean reward increase: 16.2 -> 17.3
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 340      |
| mean 100 episode reward | 17.9     |
| steps                   | 6.86e+05 |
--------------------------------------
Saving model due to mean reward increase: 17.3 -> 18.2
Saving model due to mean reward increase: 18.2 -> 18.3
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 350      |
| mean 100 episode reward | 18.4     |
| steps                   | 7.05e+05 |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 360      |
| mean 100 episode reward | 18.3     |
| steps                   | 7.24e+05 |
--------------------------------------
Saving model due to mean reward increase: 18.3 -> 18.6
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 370      |
| mean 100 episode reward | 18.6     |
| steps                   | 7.42e+05 |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 380      |
| mean 100 episode reward | 18.6     |
| steps                   | 7.59e+05 |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 390      |
| mean 100 episode reward | 18.6     |
| steps                   | 7.77e+05 |
--------------------------------------
Saving model due to mean reward increase: 18.6 -> 18.7
Saving model due to mean reward increase: 18.7 -> 19.0
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 400      |
| mean 100 episode reward | 19.1     |
| steps                   | 7.94e+05 |
--------------------------------------
Saving model due to mean reward increase: 19.0 -> 19.1
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 410      |
| mean 100 episode reward | 19       |
| steps                   | 8.13e+05 |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 420      |
| mean 100 episode reward | 19.1     |
| steps                   | 8.3e+05  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 430      |
| mean 100 episode reward | 19.1     |
| steps                   | 8.48e+05 |
--------------------------------------
Saving model due to mean reward increase: 19.1 -> 19.2
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 440      |
| mean 100 episode reward | 19.2     |
| steps                   | 8.66e+05 |
--------------------------------------
Saving model due to mean reward increase: 19.2 -> 19.3
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 450      |
| mean 100 episode reward | 19.4     |
| steps                   | 8.83e+05 |
--------------------------------------
Saving model due to mean reward increase: 19.3 -> 19.4
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 460      |
| mean 100 episode reward | 19.4     |
| steps                   | 9.02e+05 |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 470      |
| mean 100 episode reward | 19.4     |
| steps                   | 9.19e+05 |
--------------------------------------
Saving model due to mean reward increase: 19.4 -> 19.5
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 480      |
| mean 100 episode reward | 19.4     |
| steps                   | 9.37e+05 |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 490      |
| mean 100 episode reward | 19.4     |
| steps                   | 9.54e+05 |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 500      |
| mean 100 episode reward | 19.3     |
| steps                   | 9.73e+05 |
--------------------------------------
Saving model due to mean reward increase: 19.5 -> 19.6
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 510      |
| mean 100 episode reward | 19.6     |
| steps                   | 9.9e+05  |
--------------------------------------
Restored model 1 with mean reward: 19.6

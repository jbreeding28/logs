Logging to /home/jack/logs/Pong_new_solo_baseline
--------------------------------------
| % time spent exploring  | 91       |
| episodes                | 10       |
| mean 100 episode reward | -20.2    |
| steps                   | 8.14e+03 |
--------------------------------------
--------------------------------------
| % time spent exploring  | 82       |
| episodes                | 20       |
| mean 100 episode reward | -20.2    |
| steps                   | 1.74e+04 |
--------------------------------------
--------------------------------------
| % time spent exploring  | 73       |
| episodes                | 30       |
| mean 100 episode reward | -20.1    |
| steps                   | 2.67e+04 |
--------------------------------------
--------------------------------------
| % time spent exploring  | 64       |
| episodes                | 40       |
| mean 100 episode reward | -20.2    |
| steps                   | 3.58e+04 |
--------------------------------------
--------------------------------------
| % time spent exploring  | 54       |
| episodes                | 50       |
| mean 100 episode reward | -20      |
| steps                   | 4.57e+04 |
--------------------------------------
--------------------------------------
| % time spent exploring  | 45       |
| episodes                | 60       |
| mean 100 episode reward | -20      |
| steps                   | 5.53e+04 |
--------------------------------------
--------------------------------------
| % time spent exploring  | 36       |
| episodes                | 70       |
| mean 100 episode reward | -20.1    |
| steps                   | 6.43e+04 |
--------------------------------------
--------------------------------------
| % time spent exploring  | 27       |
| episodes                | 80       |
| mean 100 episode reward | -20.2    |
| steps                   | 7.34e+04 |
--------------------------------------
--------------------------------------
| % time spent exploring  | 18       |
| episodes                | 90       |
| mean 100 episode reward | -20.2    |
| steps                   | 8.2e+04  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 8        |
| episodes                | 100      |
| mean 100 episode reward | -20.2    |
| steps                   | 9.28e+04 |
--------------------------------------
Saving model due to mean reward increase: None -> -20.2
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 110      |
| mean 100 episode reward | -20.1    |
| steps                   | 1.05e+05 |
--------------------------------------
Saving model due to mean reward increase: -20.2 -> -20.1
Saving model due to mean reward increase: -20.1 -> -19.9
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 120      |
| mean 100 episode reward | -19.9    |
| steps                   | 1.2e+05  |
--------------------------------------
Saving model due to mean reward increase: -19.9 -> -19.7
Saving model due to mean reward increase: -19.7 -> -19.4
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 130      |
| mean 100 episode reward | -19.3    |
| steps                   | 1.4e+05  |
--------------------------------------
Saving model due to mean reward increase: -19.4 -> -19.1
Saving model due to mean reward increase: -19.1 -> -18.8
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 140      |
| mean 100 episode reward | -18.8    |
| steps                   | 1.62e+05 |
--------------------------------------
Saving model due to mean reward increase: -18.8 -> -18.6
Saving model due to mean reward increase: -18.6 -> -18.3
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 150      |
| mean 100 episode reward | -18.3    |
| steps                   | 1.82e+05 |
--------------------------------------
Saving model due to mean reward increase: -18.3 -> -18.1
Saving model due to mean reward increase: -18.1 -> -18.0
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 160      |
| mean 100 episode reward | -17.7    |
| steps                   | 2.06e+05 |
--------------------------------------
Saving model due to mean reward increase: -18.0 -> -17.7
Saving model due to mean reward increase: -17.7 -> -17.3
Saving model due to mean reward increase: -17.3 -> -16.8
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 170      |
| mean 100 episode reward | -16.7    |
| steps                   | 2.37e+05 |
--------------------------------------
Saving model due to mean reward increase: -16.8 -> -16.6
Saving model due to mean reward increase: -16.6 -> -16.2
Saving model due to mean reward increase: -16.2 -> -15.7
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 180      |
| mean 100 episode reward | -15.1    |
| steps                   | 2.68e+05 |
--------------------------------------
Saving model due to mean reward increase: -15.7 -> -15.1
Saving model due to mean reward increase: -15.1 -> -14.6
Saving model due to mean reward increase: -14.6 -> -14.3
Saving model due to mean reward increase: -14.3 -> -13.4
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 190      |
| mean 100 episode reward | -13.3    |
| steps                   | 3.02e+05 |
--------------------------------------
Saving model due to mean reward increase: -13.4 -> -12.7
Saving model due to mean reward increase: -12.7 -> -12.0
Saving model due to mean reward increase: -12.0 -> -11.8
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 200      |
| mean 100 episode reward | -11.1    |
| steps                   | 3.35e+05 |
--------------------------------------
Saving model due to mean reward increase: -11.8 -> -10.8
Saving model due to mean reward increase: -10.8 -> -10.1
Saving model due to mean reward increase: -10.1 -> -9.7
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 210      |
| mean 100 episode reward | -9.1     |
| steps                   | 3.64e+05 |
--------------------------------------
Saving model due to mean reward increase: -9.7 -> -8.5
Saving model due to mean reward increase: -8.5 -> -7.9
Saving model due to mean reward increase: -7.9 -> -6.8
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 220      |
| mean 100 episode reward | -6.6     |
| steps                   | 3.9e+05  |
--------------------------------------
Saving model due to mean reward increase: -6.8 -> -5.9
Saving model due to mean reward increase: -5.9 -> -5.2
Saving model due to mean reward increase: -5.2 -> -5.0
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 230      |
| mean 100 episode reward | -4.7     |
| steps                   | 4.24e+05 |
--------------------------------------
Saving model due to mean reward increase: -5.0 -> -4.4
Saving model due to mean reward increase: -4.4 -> -3.8
Saving model due to mean reward increase: -3.8 -> -3.0
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 240      |
| mean 100 episode reward | -2.3     |
| steps                   | 4.53e+05 |
--------------------------------------
Saving model due to mean reward increase: -3.0 -> -1.3
Saving model due to mean reward increase: -1.3 -> -0.1
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 250      |
| mean 100 episode reward | 0.7      |
| steps                   | 4.76e+05 |
--------------------------------------
Saving model due to mean reward increase: -0.1 -> 1.0
Saving model due to mean reward increase: 1.0 -> 1.8
Saving model due to mean reward increase: 1.8 -> 3.2
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 260      |
| mean 100 episode reward | 3.5      |
| steps                   | 5.02e+05 |
--------------------------------------
Saving model due to mean reward increase: 3.2 -> 4.0
Saving model due to mean reward increase: 4.0 -> 4.9
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 270      |
| mean 100 episode reward | 5.9      |
| steps                   | 5.26e+05 |
--------------------------------------
Saving model due to mean reward increase: 4.9 -> 6.2
Saving model due to mean reward increase: 6.2 -> 7.4
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 280      |
| mean 100 episode reward | 8.2      |
| steps                   | 5.48e+05 |
--------------------------------------
Saving model due to mean reward increase: 7.4 -> 8.2
Saving model due to mean reward increase: 8.2 -> 9.0
Saving model due to mean reward increase: 9.0 -> 9.5
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 290      |
| mean 100 episode reward | 9.6      |
| steps                   | 5.77e+05 |
--------------------------------------
Saving model due to mean reward increase: 9.5 -> 9.7
Saving model due to mean reward increase: 9.7 -> 10.4
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 300      |
| mean 100 episode reward | 11       |
| steps                   | 6e+05    |
--------------------------------------
Saving model due to mean reward increase: 10.4 -> 11.0
Saving model due to mean reward increase: 11.0 -> 11.5
Saving model due to mean reward increase: 11.5 -> 12.8
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 310      |
| mean 100 episode reward | 12.7     |
| steps                   | 6.21e+05 |
--------------------------------------
Saving model due to mean reward increase: 12.8 -> 13.0
Saving model due to mean reward increase: 13.0 -> 13.5
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 320      |
| mean 100 episode reward | 13.7     |
| steps                   | 6.42e+05 |
--------------------------------------
Saving model due to mean reward increase: 13.5 -> 14.0
Saving model due to mean reward increase: 14.0 -> 14.4
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 330      |
| mean 100 episode reward | 14.9     |
| steps                   | 6.64e+05 |
--------------------------------------
Saving model due to mean reward increase: 14.4 -> 15.1
Saving model due to mean reward increase: 15.1 -> 15.7
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 340      |
| mean 100 episode reward | 15.5     |
| steps                   | 6.89e+05 |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 350      |
| mean 100 episode reward | 15.7     |
| steps                   | 7.11e+05 |
--------------------------------------
Saving model due to mean reward increase: 15.7 -> 15.9
Saving model due to mean reward increase: 15.9 -> 16.0
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 360      |
| mean 100 episode reward | 16       |
| steps                   | 7.34e+05 |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 370      |
| mean 100 episode reward | 16       |
| steps                   | 7.59e+05 |
--------------------------------------
Saving model due to mean reward increase: 16.0 -> 16.1
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 380      |
| mean 100 episode reward | 15.8     |
| steps                   | 7.84e+05 |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 390      |
| mean 100 episode reward | 16.4     |
| steps                   | 8.06e+05 |
--------------------------------------
Saving model due to mean reward increase: 16.1 -> 16.3
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 400      |
| mean 100 episode reward | 16.3     |
| steps                   | 8.28e+05 |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 410      |
| mean 100 episode reward | 16.3     |
| steps                   | 8.5e+05  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 420      |
| mean 100 episode reward | 16.2     |
| steps                   | 8.7e+05  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 430      |
| mean 100 episode reward | 16.4     |
| steps                   | 8.89e+05 |
--------------------------------------
Saving model due to mean reward increase: 16.3 -> 16.4
Saving model due to mean reward increase: 16.4 -> 16.6
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 440      |
| mean 100 episode reward | 16.7     |
| steps                   | 9.1e+05  |
--------------------------------------
Saving model due to mean reward increase: 16.6 -> 16.8
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 450      |
| mean 100 episode reward | 16.7     |
| steps                   | 9.3e+05  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 460      |
| mean 100 episode reward | 16.8     |
| steps                   | 9.49e+05 |
--------------------------------------
Saving model due to mean reward increase: 16.8 -> 17.2
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 470      |
| mean 100 episode reward | 17.3     |
| steps                   | 9.68e+05 |
--------------------------------------
Saving model due to mean reward increase: 17.2 -> 17.3
Saving model due to mean reward increase: 17.3 -> 17.5
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 480      |
| mean 100 episode reward | 17.6     |
| steps                   | 9.87e+05 |
--------------------------------------
Saving model due to mean reward increase: 17.5 -> 17.6
Saving model due to mean reward increase: 17.6 -> 17.7
Restored model 1 with mean reward: 17.7
